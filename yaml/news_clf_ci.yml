resources:
  containers:
  - container: mlops
    image: andysong199086/news_clf:3.0

pr: none
trigger:
  branches:
    include:
    - main

variables:
  - template: env_template.yml
  - group: devops-vg

pool:
  vmImage: ubuntu-latest

stages:
- stage: 'Model_CI'
  displayName: 'Model CI'
  jobs:
  - job: 'Create_Corpus'
    displayName: 'Creating Corpus'
    container: mlops
    timeoutInMinutes: 0
    steps:
    - task: AzureCLI@1
      displayName: 'building corpus'
      name: 'getcorpus'
      inputs:
        azureSubscription: '$(WORKSPACE_SVC_CONNECTION)'
        scriptLocation: inlineScript
        workingDirectory: $(Build.SourcesDirectory)
        inlineScript: |
          set -e
          echo 'creating corpus'
          if [ ! -f 'News_Category_Dataset_v2.json.zip' ];then
            echo 'manully download the data and unzip it first!'
          fi
          unzip News_Category_Dataset_v2.json.zip
          rm News_Category_Dataset_v2.json.zip
          python py/build_corpus.py --corpus News_Category_Dataset_v2.json > corpus.txt
          wc -l corpus.txt
          head -n 5 corpus.txt
          python py/preprocessing.py --corpus corpus.txt > corpus_clean.txt
          python py/train_test_split.py --corpus corpus_clean.txt --train_ratio $(TRAIN_RATIO)
          wc -l corpus_train.txt corpus_eval.txt
          awk -F '\t' '{print tolower($2)}' corpus_train.txt > corpus_train_text.txt
          wc -l corpus_train_text.txt
          python py/build_vocab.py --tokenizer 'treebank' --max_seq_len 1024 \
          --input corpus_train_text.txt --corpus corpus_train.txt --vocab vocab_train.pkl \
          --min_freq 3 --mode $(MODEL_MODE) --lower --pretrained_vectors
          if [ ! -f 'vocab_train.pkl' ];then
            echo 'vocab_train.pkl not produced'
            exit 1
          else
            echo 'vocab_train.pkl found'
          fi
          export SUBSCRIPTION_ID=$(az account show --query id -o tsv)
          python azure/upload.py --corpus_train corpus_train.txt --corpus_eval corpus_eval.txt --vocab vocab_train.pkl
#  - job: 'Build_Pipeline'
#    dependsOn: 'Create_Corpus'
#    condition: succeeded()
#    displayName: 'Build pipeline'
#    container: mlops
#    timeoutInMinutes: 0
#    steps:
#    - task: AzureCLI@1
#      inputs:
#        azureSubscription: '$(WORKSPACE_SVC_CONNECTION)'
#        scriptLocation: inlineScript
#        workingDirectory: $(Build.SourcesDirectory)
#        inlineScript: |
#          set -e
#          export SUBSCRIPTION_ID=$(az account show --query id -o tsv)
#          python azure/pipeline.py
#  - job: 'Run_Pipeline'
#    dependsOn: 'Create_Corpus'
#    condition: succeeded()
#    displayName: 'running pipeline'
#    container: mlops
#    timeoutInMinutes: 0
#    variables:
#      TRAIN_DATA: $[ dependencies.Create_Corpus.outputs['getcorpus.train_data'] ]
#      EVAL_DATA: $[ dependencies.Create_Corpus.outputs['getcorpus.eval_data'] ]
#      VOCAB: $[ dependencies.Create_Corpus.outputs['getcorpus.vocab'] ]
#    steps:
#    - task: AzureCLI@1
#      inputs:
#        azureSubscription: '$(WORKSPACE_SVC_CONNECTION)'
#        scriptLocation: inlineScript
#        workingDirectory: $(Build.SourcesDirectory)
#        inlineScript: |
#          set -e
#          export SUBSCRIPTION_ID=$(az account show --query id -o tsv)
#          python azure/pipeline_run.py --vocab '$(VOCAB)' --train_corpus '$(TRAIN_DATA)' --eval_corpus '$(EVAL_DATA)'
        
          
