resources:
  containers:
  - container: mlops
    image: andysong199086/news_clf:3.0

pr: none
trigger:
  branches:
    include:
    - main

variables:
  - template: env_template.yml
  - group: devops-vg

pool:
  vmImage: ubuntu-latest

stages:
- stage: 'Model_CI'
  displayName: 'Model CI'
  variables:
    BUILD_ID: '$(BUILD.BUILDID)'
    BUILD_URL: '$(SYSTEM.COLLECTIONURI)$(SYSTEM.TEAMPROJECT)/_build/results?buildId=$(BUILD.BUILDID)'
  jobs:
  - job: 'Create_Corpus'
    displayName: 'Creating Corpus'
    container: mlops
    condition: eq(variables['RUN_MODEL_CI'],'true')
    timeoutInMinutes: 0
    steps:
    - task: AzureCLI@1
      displayName: 'building corpus'
      name: 'getcorpus'
      inputs:
        azureSubscription: '$(WORKSPACE_SVC_CONNECTION)'
        scriptLocation: inlineScript
        workingDirectory: $(Build.SourcesDirectory)
        inlineScript: |
          set -e
          echo 'creating corpus'
          if [ ! -f 'News_Category_Dataset_v2.json.zip' ];then
            echo 'manully download the data and unzip it first!'
          fi
          unzip News_Category_Dataset_v2.json.zip
          rm News_Category_Dataset_v2.json.zip
          python py/build_corpus.py --corpus News_Category_Dataset_v2.json > corpus.txt
          wc -l corpus.txt
          head -n 5 corpus.txt
          python py/preprocessing.py --corpus corpus.txt > corpus_clean.txt
          python py/train_test_split.py --corpus corpus_clean.txt --train_ratio $(TRAIN_RATIO)
          wc -l corpus_train.txt corpus_eval.txt
          awk -F '\t' '{print tolower($2)}' corpus_train.txt > corpus_train_text.txt
          wc -l corpus_train_text.txt
          python py/build_vocab.py --tokenizer 'treebank' --max_seq_len 1024 \
          --input corpus_train_text.txt --corpus corpus_train.txt --vocab vocab_train.pkl \
          --min_freq 3 --mode $(FASTTEXT_MODE) --lower --pretrained_vectors
          if [ ! -f 'vocab_train.pkl' ];then
            echo 'vocab_train.pkl not produced'
            exit 1
          else
            echo 'vocab_train.pkl found'
          fi
          export SUBSCRIPTION_ID=$(az account show --query id -o tsv)
          python azure/upload.py --corpus_train corpus_train.txt --corpus_eval corpus_eval.txt --vocab vocab_train.pkl
  - job: 'Build_Pipeline'
    displayName: 'Build pipeline'
    container: mlops
    timeoutInMinutes: 0
    steps:
    - task: AzureCLI@1
      inputs:
        azureSubscription: '$(WORKSPACE_SVC_CONNECTION)'
        scriptLocation: inlineScript
        workingDirectory: $(Build.SourcesDirectory)
        inlineScript: |
          set -e
          export SUBSCRIPTION_ID=$(az account show --query id -o tsv)
          python azure/pipeline.py
  - job: 'Run_Pipeline'
    dependsOn: 'Build_Pipeline'
    condition: succeeded()
    displayName: 'running pipeline'
    container: mlops
    timeoutInMinutes: 0
    steps:
    - task: AzureCLI@1
      inputs:
        azureSubscription: '$(WORKSPACE_SVC_CONNECTION)'
        scriptLocation: inlineScript
        workingDirectory: $(Build.SourcesDirectory)
        inlineScript: |
          set -e
          export SUBSCRIPTION_ID=$(az account show --query id -o tsv)
          python azure/pipeline_run.py --bidirectional 
        
          
